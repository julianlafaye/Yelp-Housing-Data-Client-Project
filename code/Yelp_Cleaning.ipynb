{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "(4026, 17)\n(1778, 17)\n"
        }
      ],
      "source": [
        "# %% Imports\n",
        "import pandas as pd\n",
        "import missingno as msno\n",
        "import numpy as np\n",
        "\n",
        "# Load in Raw Data\n",
        "yelp = pd.read_csv(f\"../data/yelp_entries_gacities.csv\")\n",
        "print(yelp.shape)\n",
        "yelp.drop_duplicates(subset='alias', keep=\"first\", inplace=True)\n",
        "print(yelp.shape)\n",
        "yelp.reset_index()\n",
        "yelp = yelp.drop(columns=['zip_code'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {},
      "outputs": [],
      "source": [
        "# This goes to all of the dictionaries stored as objects, evaluates them, and extracts their values as columns\n",
        "coordinates_list = yelp.coordinates.values.tolist()\n",
        "coordinates_df = pd.DataFrame([eval(x) for x in coordinates_list])\n",
        "\n",
        "location_list = yelp.location.values.tolist()\n",
        "location_df = pd.DataFrame([eval(x) for x in location_list])\n",
        "categories_list = yelp.categories.values.tolist()\n",
        "category_df = pd.DataFrame([eval(x) for x in categories_list], columns=[\"category_1\",\n",
        "                                                                \"category_2\",\n",
        "                                                                \"category_3\",\n",
        "                                                                ])\n",
        "\n",
        "location_df.drop(labels=['address3', 'address2'], axis=1, inplace = True) # Droping the extra address columns\n",
        "\n",
        "# Categories needed some extra love (they were stored in nested dictionaries)\n",
        "category_df[\"category_1\"] = category_df['category_1'].map(lambda x: x['alias'])\n",
        "category_df[\"category_2\"] = category_df['category_2'].map(lambda x: x['alias'] if type(x) == dict else x)\n",
        "category_df[\"category_3\"] = category_df['category_3'].map(lambda x: x['alias'] if type(x) == dict else x)\n",
        "\n",
        "# Combining all the datasets\n",
        "df = yelp.join(coordinates_df)\n",
        "df = df.join(location_df)\n",
        "df = df.join(category_df)\n",
        "\n",
        "# Droping anything that will not be helpful\n",
        "df = df[df['state'] == 'GA']\n",
        "df= df[['name', \n",
        "        'price', \n",
        "        'rating', 'review_count',\n",
        "        'latitude','longitude', \n",
        "        'city', 'state', 'zip_code',\n",
        "        'category_1', 'category_2', 'category_3']]\n",
        "# To CSV\n",
        "df.to_csv('../data/yelp_gacities_clean.csv', index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Code for combining X and y:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {},
      "outputs": [],
      "source": [
        "## Read in Data and drop any rows missing location values ###\n",
        "yelp_clean_df = pd.read_csv(\"../data/yelp_gacities_clean.csv\") # This line is unessessary now.\n",
        "income_df = pd.read_csv('../data/zips_list.csv')\n",
        "yelp_clean_df.dropna(subset=['zip_code', 'latitude', 'longitude'], inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ### I've also added a variable to deteremine if it is a park or not, just for fun\n",
        "# ## it does not work anymore\n",
        "# yelp_clean_df['is_park'] = np.where(np.logical_and(yelp_clean_df['name'].str.lower().str.contains(\"park\"), \n",
        "#                                              yelp_clean_df['price'].isna()), 1, 0)\n",
        "# yelp_clean_df[yelp_clean_df['is_park'] == 1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {},
      "outputs": [],
      "source": [
        "## This is the actual combining part:\n",
        "cdf = pd.merge(yelp_clean_df, income_df, on=\"zip_code\")\n",
        "# I'm also ordinalizing the price data feel free to suggest something else, \n",
        "# most of the data without pricing was free or an activity so I believe this works(open to suggestions)\n",
        "recode = {np.nan : 0, '$' : 1, '$$' : 2, '$$$' : 3, '$$$$' : 4 }\n",
        "cdf['price'].replace(recode, inplace=True) # Recode\n",
        "# To CSV\n",
        "cdf.to_csv('../data/yelp_income_gacities_clean.csv', index= False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6-final"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}